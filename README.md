
# Movie LiveRoom + Real-Time Data Dashboard

> Kafka + Flink + Spring Boot + WebSocket + Docker Compose + systemd HA automation
> Real-time event ingestion, analytics, and dashboard for interactive live streaming.

---

## â­ Project Overview

This project provides a **full-stack real-time analytics platform** for live streaming scenarios:

* **Kafka**: Real-time event ingestion (chat, like, gift, etc.)
* **Flink**: Streaming analytics, aggregation, and ETL
* **Spring Boot**: Backend API & WebSocket push
* **React/Vue**: (Optional) Real-time data dashboard
* **Docker Compose**: One-click stack deployment
* **systemd**: High-availability (HA), automatic startup, periodic job submission

---

## ğŸ Quick Start (Dev/Test)

### 1. Requirements

* Docker & Docker Compose
* Recommended: Linux (Ubuntu 20.04+ or similar)

### 2. Deploy all services

```bash
git clone https://github.com/Islene888/movie_liveroom.git
cd movie_liveroom
docker-compose up -d
```

Services include: Zookeeper, Kafka, Flink (JobManager/TaskManager), Backend API, (Frontend dashboard optional)

### 3. Service Endpoints

| Service          | Public Access URL / Note                               |
| ---------------- |--------------------------------------------------------|
| Backend API      | [http://34.45.211.142:8080](http://34.45.211.142:8080) |
| Frontend UI      | [http://34.45.211.142:3000](http://34.45.211.142:3000) |
| Flink UI         | [http://34.45.211.142:8081](http://34.45.211.142:8081) |
| Kafka (internal) | Use `kafka:29092` **inside containers only**           |

---

## ğŸ›°ï¸ Flink Job Submission & Automation

### Manual Flink job submission

1. **Build your JAR**

   ```bash
   cd flinkjob
   mvn clean package -DskipTests
   ```

2. **Copy & submit**

   ```bash
   docker cp target/flinkjob-0.0.1-SNAPSHOT.jar jobmanager:/opt/flink/usrlib/
   docker exec -it jobmanager flink run -c com.ella.flinkjob.FlinkEventTypeAggregator /opt/flink/usrlib/flinkjob-0.0.1-SNAPSHOT.jar
   ```

### Recommended: Automated job submit via systemd

* Place `submit-flink-job.sh` in `/usr/local/bin/`
* Create `/etc/systemd/system/movie-flinkjob.service` to automate submission on boot or timer
* (See below for HA / systemd config)

#### Sample submission script

```bash
#!/usr/bin/env bash
set -euo pipefail
JM_REST_URL="http://localhost:8081"
JAR_PATH="/home/islenezhao/movie_liveroom/flinkjob/target/flinkjob-0.0.1-SNAPSHOT.jar"
MAIN_CLASS="com.ella.flinkjob.FlinkEventTypeAggregator"
UPLOAD_JSON=$(curl -s -X POST "${JM_REST_URL}/jars/upload" -F "jarfile=@${JAR_PATH}")
JAR_ID=$(echo "$UPLOAD_JSON" | python3 -c 'import sys,json;print(json.load(sys.stdin)["filename"].split("/")[-1])')
RUN_JSON=$(curl -s -X POST "${JM_REST_URL}/jars/${JAR_ID}/run" -H "Content-Type: application/json" -d "{\"entryClass\":\"${MAIN_CLASS}\"}")
echo "Flink Job submitted: $(echo $RUN_JSON | python3 -c 'import sys,json;print(json.load(sys.stdin).get("jobid",""))')"
```

---

## âš™ï¸ systemd Service & HA Ops

### 1. Full stack compose service

`/etc/systemd/system/movie_liveroom.service`:

```ini
[Unit]
Description=Movie LiveRoom Full Stack
After=network.target

[Service]
Type=oneshot
WorkingDirectory=/home/islenezhao/movie_liveroom
ExecStart=/usr/bin/docker-compose up -d
RemainAfterExit=yes

[Install]
WantedBy=multi-user.target
```

```bash
sudo systemctl daemon-reload
sudo systemctl enable movie_liveroom.service
sudo systemctl start movie_liveroom.service
```

### 2. Flink job submit via systemd

`/etc/systemd/system/movie-flinkjob.service`:

```ini
[Unit]
Description=Submit Flink Job via REST API
After=movie_liveroom.service
Requires=movie_liveroom.service

[Service]
Type=oneshot
ExecStart=/usr/local/bin/submit-flink-job.sh

[Install]
WantedBy=multi-user.target
```

**Optional timer** (`/etc/systemd/system/movie-flinkjob.timer`) for auto-resubmit every 10 minutes:

```ini
[Unit]
Description=Run Flink submit script every 10 minutes
[Timer]
OnBootSec=2min
OnUnitActiveSec=10min
Persistent=true
[Install]
WantedBy=timers.target
```

---

## ğŸ§© Config & Troubleshooting

* **Kafka address:** Use `kafka:29092` (not `localhost:9092`) inside containers
* **App/config changes:** Rebuild corresponding Docker images, restart containers
* **Large files:** Use `.gitignore` to skip logs/jars, or [Git LFS](https://git-lfs.github.com/)
* **Git push failures:** For files >100MB, see LFS or remove files from history

---

## ğŸ’¡ FAQ / DevOps Tips

| Problem                                   | Solution                                       |
| ----------------------------------------- | ---------------------------------------------- |
| Flink CLI "REST advertised address" error | Use REST API submission script (see above)     |
| Kafka "localhost:9092" connection fails   | Use service name\:port, e.g. `kafka:29092`     |
| App/image changes not reflected           | Rebuild image, `docker-compose up -d`          |
| Container crash/restart                   | Handled by systemd + Docker Compose            |
| Flink job missing after restart           | Use systemd timer + REST script for auto-resub |
| Git push fails for large files            | Use Git LFS or exclude in `.gitignore`         |

---

## ğŸ“¦ Recommended Production Enhancements

* External DBs (MySQL, ClickHouse) should use persistent storage/volumes
* Frontend can be served by nginx as static files for performance
* For true Flink HA, enable checkpoints + ZooKeeper

---

# ç”µå½±ç›´æ’­é—´ + å®æ—¶æ•°æ®çœ‹æ¿

> Kafka + Flink + Spring Boot + WebSocket + Docker Compose + systemd è‡ªåŠ¨é«˜å¯ç”¨
> é¢å‘äº’åŠ¨ç›´æ’­åœºæ™¯çš„å¼¹å¹•ã€ç‚¹èµç­‰å®æ—¶äº‹ä»¶é‡‡é›†ã€å¤„ç†å’Œå¤§å±å¯è§†åŒ–å±•ç¤º

---

## â­ é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®æ˜¯ä¸€ä¸ª**å…¨æ ˆå®æ—¶æ•°æ®åˆ†æå¹³å°**ï¼Œç”¨äºç›´æ’­äº’åŠ¨ã€å®æ—¶ç»Ÿè®¡ä¸å¤§å±å±•ç¤ºï¼ŒæŠ€æœ¯æ ˆåŒ…æ‹¬ï¼š

* **Kafka**ï¼šé‡‡é›†å®æ—¶å¼¹å¹•ã€ç‚¹èµã€é€ç¤¼ç­‰äº‹ä»¶
* **Flink**ï¼šæµå¼åˆ†æã€èšåˆä¸ ETL
* **Spring Boot**ï¼šåç«¯ API ä¸ WebSocket æ¨é€
* **React/Vue**ï¼ˆå¯é€‰ï¼‰ï¼šå®æ—¶æ•°æ®å¯è§†åŒ–å¤§å±
* **Docker Compose**ï¼šä¸€é”®å…¨æ ˆéƒ¨ç½²
* **systemd**ï¼šé«˜å¯ç”¨åå°æ‰˜ç®¡ã€è‡ªåŠ¨é‡å¯ä¸ä½œä¸šå®šæ—¶æäº¤

---

## ğŸ å¿«é€Ÿå¯åŠ¨ï¼ˆå¼€å‘/æµ‹è¯•ç¯å¢ƒï¼‰

### 1. ç¯å¢ƒè¦æ±‚

* Docker & Docker Compose
* å»ºè®® Linuxï¼ˆå¦‚ Ubuntu 20.04+ï¼‰

### 2. ä¸€é”®å¯åŠ¨å…¨æ ˆæœåŠ¡

```bash
git clone https://github.com/Islene888/movie_liveroom.git
cd movie_liveroom
docker-compose up -d
```

å¯åŠ¨ååŒ…æ‹¬ï¼šZookeeperã€Kafkaã€Flinkï¼ˆJobManager/TaskManagerï¼‰ã€åç«¯æœåŠ¡ã€ï¼ˆå¯é€‰å‰ç«¯å¤§å±ï¼‰

### 3. æœåŠ¡è®¿é—®å…¥å£

| æœåŠ¡          | å…¬ç½‘è®¿é—®åœ°å€                                                 |
| ----------- | ------------------------------------------------------ |
| åç«¯ API      | [http://34.45.211.142:8080](http://34.45.211.142:8080) |
| å‰ç«¯å¤§å±        | [http://34.45.211.142:3000](http://34.45.211.142:3000) |
| Flink UI    | [http://34.45.211.142:8081](http://34.45.211.142:8081) |
| Kafkaï¼ˆå®¹å™¨å†…éƒ¨ï¼‰ | ä»…é™å®¹å™¨é—´ç”¨ `kafka:29092`ï¼Œä¸»æœºæ— æ³•ç›´æ¥è®¿é—®                          |

---

## ğŸ›°ï¸ Flink ä½œä¸šæäº¤ä¸è‡ªåŠ¨åŒ–

### æ‰‹åŠ¨æäº¤ Flink ä»»åŠ¡

1. **æ‰“åŒ… JAR**

   ```bash
   cd flinkjob
   mvn clean package -DskipTests
   ```

2. **æ‹·è´å¹¶æäº¤**

   ```bash
   docker cp target/flinkjob-0.0.1-SNAPSHOT.jar jobmanager:/opt/flink/usrlib/
   docker exec -it jobmanager flink run -c com.ella.flinkjob.FlinkEventTypeAggregator /opt/flink/usrlib/flinkjob-0.0.1-SNAPSHOT.jar
   ```

### æ¨èæ–¹å¼ï¼šsystemd è‡ªåŠ¨æäº¤ï¼ˆé«˜å¯ç”¨ï¼‰

* å°† `submit-flink-job.sh` æ”¾åˆ° `/usr/local/bin/`
* é…ç½® `/etc/systemd/system/movie-flinkjob.service`ï¼Œæ”¯æŒå¼€æœºè‡ªåŠ¨/å®šæ—¶æäº¤
* å®šæ—¶å™¨å¯è‡ªåŠ¨è¡¥äº¤ä»»åŠ¡ï¼Œæå‡é«˜å¯ç”¨

#### ç¤ºä¾‹è‡ªåŠ¨æäº¤è„šæœ¬

```bash
#!/usr/bin/env bash
set -euo pipefail
JM_REST_URL="http://localhost:8081"
JAR_PATH="/home/islenezhao/movie_liveroom/flinkjob/target/flinkjob-0.0.1-SNAPSHOT.jar"
MAIN_CLASS="com.ella.flinkjob.FlinkEventTypeAggregator"
UPLOAD_JSON=$(curl -s -X POST "${JM_REST_URL}/jars/upload" -F "jarfile=@${JAR_PATH}")
JAR_ID=$(echo "$UPLOAD_JSON" | python3 -c 'import sys,json;print(json.load(sys.stdin)["filename"].split("/")[-1])')
RUN_JSON=$(curl -s -X POST "${JM_REST_URL}/jars/${JAR_ID}/run" -H "Content-Type: application/json" -d "{\"entryClass\":\"${MAIN_CLASS}\"}")
echo "Flink Job submitted: $(echo $RUN_JSON | python3 -c 'import sys,json;print(json.load(sys.stdin).get("jobid",""))')"
```

---

## âš™ï¸ systemd æœåŠ¡ä¸é«˜å¯ç”¨è¿ç»´

### 1. å…¨æ ˆ compose æœåŠ¡æ‰˜ç®¡

`/etc/systemd/system/movie_liveroom.service`:

```ini
[Unit]
Description=Movie LiveRoom Full Stack
After=network.target

[Service]
Type=oneshot
WorkingDirectory=/home/islenezhao/movie_liveroom
ExecStart=/usr/bin/docker-compose up -d
RemainAfterExit=yes

[Install]
WantedBy=multi-user.target
```

```bash
sudo systemctl daemon-reload
sudo systemctl enable movie_liveroom.service
sudo systemctl start movie_liveroom.service
```

### 2. Flink ä½œä¸šè‡ªåŠ¨æäº¤ï¼ˆå«å®šæ—¶è¡¥äº¤ï¼‰

`/etc/systemd/system/movie-flinkjob.service`:

```ini
[Unit]
Description=Submit Flink Job via REST API
After=movie_liveroom.service
Requires=movie_liveroom.service

[Service]
Type=oneshot
ExecStart=/usr/local/bin/submit-flink-job.sh

[Install]
WantedBy=multi-user.target
```

**å¯é€‰ï¼šå®šæ—¶å™¨ï¼ˆæ¯10åˆ†é’Ÿè¡¥æäº¤ï¼‰** `/etc/systemd/system/movie-flinkjob.timer`:

```ini
[Unit]
Description=Run Flink submit script every 10 minutes
[Timer]
OnBootSec=2min
OnUnitActiveSec=10min
Persistent=true
[Install]
WantedBy=timers.target
```

---

## ğŸ§© é…ç½®è¯´æ˜ä¸å¸¸è§é—®é¢˜

* **Kafka åœ°å€**ï¼šå®¹å™¨å†…éƒ¨ç»Ÿä¸€ç”¨ `kafka:29092`ï¼Œä¸è¦ç”¨ localhost:9092
* **ä»£ç /é…ç½®å˜åŠ¨**ï¼šé‡å»ºé•œåƒå¹¶é‡å¯å®¹å™¨
* **å¤§æ–‡ä»¶ç®¡ç†**ï¼šæ—¥å¿—/jar/zk-log ç­‰åº” `.gitignore`ï¼Œæˆ–ç”¨ [Git LFS](https://git-lfs.github.com/)
* **Git å¤§æ–‡ä»¶ push æŠ¥é”™**ï¼šè¶… 100MB å»ºè®® LFS æˆ–ä»å†å²è®°å½•ä¸­ç§»é™¤

---

## ğŸ’¡ FAQ / è¿ç»´ç»éªŒ

| é—®é¢˜ç°è±¡                      | è§£å†³åŠæ³•                                |
| ------------------------- | ----------------------------------- |
| Flink CLI â€œREST å¹¿å‘Šåœ°å€â€æŠ¥é”™   | æ¨èç”¨ REST API è„šæœ¬æäº¤ä»»åŠ¡                 |
| Kafka â€œlocalhost:9092â€è¿ä¸ä¸Š | ç”¨ `kafka:29092` å®¹å™¨æœåŠ¡åç«¯å£             |
| é•œåƒ/é…ç½®å˜æ›´æ— æ•ˆ                 | é‡æ–° build é•œåƒå¹¶ `docker-compose up -d` |
| å®¹å™¨æŒ‚æ‰è‡ªåŠ¨é‡å¯                  | äº¤ç»™ systemd + Docker Compose         |
| Flink ä½œä¸šé‡å¯åæ¶ˆå¤±             | systemd timer + REST è„šæœ¬è‡ªåŠ¨è¡¥äº¤         |
| Git æ¨é€å¤§æ–‡ä»¶å¤±è´¥               | ç”¨ Git LFS æˆ– `.gitignore` æ’é™¤         |

---

## ğŸ“¦ ç”Ÿäº§éƒ¨ç½²å»ºè®®

* MySQLã€ClickHouse ç­‰å¤–éƒ¨ DB æ¨èæŒ‚è½½æ•°æ®ç›˜æŒä¹…åŒ–
* å‰ç«¯é™æ€é¡µé¢å»ºè®®ç”¨ nginx æœåŠ¡
* Flink ç”Ÿäº§ç¯å¢ƒå»ºè®®å¼€å¯ checkpoint + ZooKeeper å®ç°çœŸæ­£ HA

